---
layout: post
title: Lookout Zillow Here Comes Jestimate!
subtitle: Using Machine Learning to Predict San Francisco Home Prices
image: '/img/SF Map.png'
comments: true
published: false
---

As someone with expertise in both real estate and data science, I’ve always been fascinated by Zillow’s Zestimate.  In the spirit of competition I’ve developed Jim’s estimate or Jestimate!

Jestimates for 2018 San Francisco Single-Family Homes

The following interactive map contains 2018 home sales in San Francisco by neighborhood.  Click on the neighborhood and then click on a home in the data table to see the Jestimate results versus the actual sales price.

<iframe src="https://sf-2018-sales.herokuapp.com/SF_2018_Sales" width="1200" height="800" style="border: none;"></iframe>

Zestimate uses a proprietary machine learning formula to estimate the current market value of a home.  In the real estate field, agents constantly battle homeowners over the market value of their home as in “You say my home is worth $1 million, but Zillow says my home is worth $1.2 million.”  Which number do you think the homeowner prefers when it comes to selling the property?

An agent’s market analysis of a property is almost always the best approach to determining the current market value of a property since an agent will actually look at the property, look at comparable properties and analyze the local market conditions.  Information such as a crack in the foundation, a 25 year old roof, an illegal addition or other undocumented defects in the property aren’t available for analysis by machine learning formulas.  An agent simply has access to more and better data than a machine learning formula.

However, the time and effort needed by an agent to produce an accurate market analysis is not practical for estimating a large number of home values.  This is where a predictive engine such as Zestimate provides value.

With that in mind, I wanted to see how well I could build a predictive engine for San Francisco single family home sales.  Can one man, a Mac and Colab beat Zillow?  Follow along and find out!

### A Word About the Code

All the code, data and associated files for the project can be accessed at my [GitHub][1].  The project is separated into two Colab notebooks.  One runs the linear regression model and the other produces the interactive map using a Bokeh server on Heroku.

### The Project Goal and Data

The goal of the project is to predict the prices of a single-family homes in San Francisco in 2018.

Since I have a real estate license I have access to the San Francisco MLS which I used to download 10 years (2009 – 2018) of single-family home sales.  The raw data consists of 23,711 sales over the ten years.  To this raw data, longitude, latitude and elevation were added using geocoding ([geocoding.geo.census.gov][2] for lat/long, [viewer.nationalmap.gov][3] for elevation.)

From the raw data the following outliers representing 1.6% of the data were removed:

1)	Homes with 7+ baths
2)	Homes with 8+ bedrooms
3)	Homes with lots over 10,000SF 
4)	Homes with 14+ rooms
5)	Homes with a sales price over $10 million

An important piece of data, house square footage, was zero for about 16% of the data.  I tried the model using the average square footage by bedroom for all single-family homes as the fill value and also by removing the homes with zero values.  While the model performed adequately with the fill values, I opted to remove the zero value homes in order to maximize the performance of the model.  The final tally leaves about 82% of the data or 19,497 home sales.

The raw data consists of 40 features, 20 numeric and 20 categorical.  A quick look at the correlation matrix provides some clues into the relationship between the numeric features.

![Correlation Matrix - 1](/img/jestimate/Pearson Correlation - 1.png)





[1]: <https://github.com/JimKing100/Jestimate_Live> 
[2]: <https://geocoding.geo.census.gov> 
[3]: <https://viewer.nationalmap.gov/apps/bulk_pqs/>
[4]: <> 
[5]: <> 
