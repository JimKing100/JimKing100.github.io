---
layout: post
title: How to Implement a Decision Tree Classifier in Python
subtitle: Create a Decision Tree Classifier from Scratch
image: '/img/nfl/football.gif'
comments: true
published: false
---

A decision tree is a popular and powerful method for making predictions in data science.  Decision trees also form the foundation for other popular ensemble methods such as bagging, boosting and gradient boosting.  Its popularity is due to the simplicity of the technique making it easy to understand.  We are going to implement a decision tree from scratch and use it for several classification problems.  First, lets start with a simple classification example to explain how a decision tree works.

### A Simple Example

Let's say we have 10 rectangles of various widths and heights.  Five of the rectangles are purple and five are yellow.  The data is shown below with X1 representing the width, X2 representing the height and Y representing the classes of 0 for purple rectangles and 1 for yellow rectangles:

![Rectangle Data](/img/dtree/rectangle_data.png)

Graphing the rectangles we can very clearly see the separate classes.

![Rectangle Graph](/img/dtree/rectangle_graph.png)

Based on the rectangle data, we can build a simple decision tree to make forecasts.  In the decision tree below we start with the top-most box which represents the root of the tree.  The first line depicts the optimal initial decision of splitting the tree based on the width (X1) being less than 5.3.  The second line represents the initial Gini score which we will go into more detail later.  The third line represents the number of samples at this level - in this case 10.  The fourth line represents the number of items in each class - 5 for purple rectangles and 5 for yellow rectangles.

![Rectangle Decision Tree](/img/dtree/rectangle_dtree.png)






