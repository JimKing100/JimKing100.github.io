---
layout: post
title: Data Visualization - Advanced Bokeh Techniques
subtitle: Bokeh Interactive Maps, DataTables, TextInput, Document Layout and Debugging
image: '/img/SF Map.png'
comments: true
published: false
---

If you are looking to create powerful data visualizations then you should consider using Bokeh.  In an earlier article, I demonstrated how to create an interactive geographic map using Bokeh ([click here][1]).  This article will take it a step further and demonstrate how to use an interactive map with a data table and text fields organized using a Bokeh layout to create an interactive dashboard for displaying data.  I will also demonstrate several methods for debugging the code which also provides some insight into the structures used in Bokeh.

First, let's take a look at the finished product which appeared in the article "[Look Out Zillow Here Comes Jestimate!][2]":

<iframe src="https://sf-real-estate.herokuapp.com/SF_Real_Estate_Project" width="950" height="775" style="border: none;"></iframe>

If you'd like to understand how to develop a similar visualization follow along as I step you through the process.

### A Word About the Code

All the code, data and associated files for the project can be accessed at my [GitHub][3].  The project is separated into two Colab notebooks.  One runs the linear regression model (creating the data for the visualization) and the other produces the interactive visualization using a Bokeh server on Heroku.

### Installs and Imports

Let's start with the installs and imports you will need for the graphs. Pandas, numpy and math are standard Python libraries used to clean and wrangle the data. The geopandas, json and bokeh imports are libraries needed for the mapping.

I work in Colab and needed to install fiona and geopandas.  While you are developing the application in Colab, you will need to keep these installs in the code.  However, once you start testing with the Bokeh server you will need to comment out these installs as Bokeh chokes on the magic commands (!pip install...).

```
# Install fiona - need to comment out for transfer to live site.
# Turn on for running in a notebook
%%capture
!pip install fiona

# Install geopandas - need to comment out for tranfer to live site.
# Turn on for running in a notebook
%%capture
!pip install geopandas
```

```
# Import libraries
import pandas as pd
import numpy as np
import math

import geopandas
import json

from bokeh.io import output_notebook, show, output_file
from bokeh.plotting import figure
from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar, NumeralTickFormatter
from bokeh.palettes import brewer

from bokeh.io.doc import curdoc
from bokeh.models import Slider, HoverTool, Select, TapTool, CustomJS, ColumnDataSource, TableColumn, DataTable, CDSView, GroupFilter
from bokeh.layouts import widgetbox, row, column, gridplot
from bokeh.models.widgets import TextInput
```

### Data Loading, Cleaning and Wrangling

As the focus of this article is on the creation of interactive dashboard, I will briefly describe the steps used to load, clean and wrangle the data. You can view the full cleaning and wrangling [here][4] if you are interested.

There are three pieces of data used in the application:  neighborhood data used to show aggregate statistics for 2018 for the neighborhood, display data for each individual property sold in 2018 produced by the linear regression program, and mapping data for drawing the map.

#### Neighborhood Data

Since I have a real estate license I have access to the San Francisco MLS which I used to download 10 years (2009 â€“ 2018) of single-family home sales into the **sf_data** dataframe.  The raw data consists of 23,711 sales over the ten years.  To this raw data, longitude, latitude and elevation were added using geocoding ([geocoding.geo.census.gov][5] for lat/long, [viewer.nationalmap.gov][6] for elevation.)

From the raw data the following outliers representing 1.6% of the data were removed:

1.	Homes with 7+ baths
2.	Homes with 8+ bedrooms
3.	Homes with lots over 10,000SF 
4.	Homes with 14+ rooms
5.	Homes with a sales price over $10 million

An important piece of data, house square footage, was zero for about 16% of the data.  I opted to remove the zero value homes in order to maximize the performance of the model.  The final tally leaves about 82% of the data or 19,497 home sales.

A key column of the data is the neighborhood code which needs to match the mapping code for the neighborhood. This will allow us to merge the data with the map. A dictionary is used to change the neighborhood codes in the data to match the neighborhood codes in the map.

Finally a year and price per square foot column are added to **sf_data** and the **sf_data** is summarized using groupby and aggregate functions to create the final **neighborhood_data** dataframe **for the 2018 data only** with all numeric fields converted to integer values for ease in displaying the data:

#### neighborhood_data DataFrame - 2018 Data Only

![neighborhood_data DataFrame](/img/jestimate/neighborhood_data.png)

#### Individual Property Display Data

In my article "[Look Out Zillow Here Comes Jestimate!][2]" I use linear regression to create estimates for single-family home sales in 2018 in San Francisco.  The final product is a dataframe named **display_data** that is used as input to this display application.

#### diplay_data DataFrame






*This is Part of a Series of Articles Exploring San Francisco Real Estate Data*

*San Francisco Real Estate Data Source:  San Francisco MLS, 2009-2018 Data*

[1]: <https://towardsdatascience.com/how-to-create-an-interactive-geographic-map-using-python-and-bokeh-12981ca0b567> 
[2]: <https://medium.com/p/look-out-zillow-here-comes-jestimate-145a96efbfbb?source=email-607257182a94--writer.postDistributed&sk=c7ba752420820a3ef1b8b7cabf535b47> 
[3]: <https://github.com/JimKing100/Jestimate_Live> 
[4]: <https://github.com/JimKing100/Jestimate_Live/blob/master/Final_SF_Map_Code.ipynb> 
[5]: <https://geocoding.geo.census.gov> 
[6]: <https://viewer.nationalmap.gov/apps/bulk_pqs/> 



