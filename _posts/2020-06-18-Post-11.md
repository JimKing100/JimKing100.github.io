---
layout: post
title: Using a Neural Network to Predict Fantasy Football Points
subtitle: A Fantasy Football Trade Analyzer Using RNN-LSTM, ARIMA, XGBoost and Dash
image: '/img/nfl/football.gif'
comments: true
published: false
---

While the complete code for predicting fantasy football points is quite involved, let's take a closer look at the core RNN-LSTM code using one player as an example.  We are going to use Aaron Rodgers, the quarterback for the Green Bay Packers.  Aaron is an excellent test case as he started his NFL career in 2005 providing 15 years of data.  In addition, he did not suffer any significant injuries during the 2019 season.

The actual points for each 2019 NFL player is stored in the **original_df** dataframe.  The first five columns of the dataframe contain descriptive features for each player.  The next 320 columns contain the actual fantasy football points for each game from 2000 to 2019 for each player (16 games per season x 20 seasons = 320 data points).  These values are Nan until the player's first NFL season.  So Aaron Rodgers actual data does not begin until column 85 (16 x 5 = 80 games until the 2005 season plus the 5 descriptive columns).

![original_df DataFrame](/img/nfl/original_df.png)

The initial call to the RNN-LSTM prediction function **lstm_pred** occurs in the function named **main**.  The input to the function consists of:

**player** = 'Aaron Rodgers' (This is the name of the player)  
**n_periods** = 16  (In this example we are beginning at the start of the season and predicting all 16 games of the 2019 season)  
**col** = 85 (In the dataframe containing the actual fantasy football points Aaron's 2005 data begins in the 85th column)  

```
pred_points = lstm_pred(player, n_periods, col)
```
Using these three inputs, let's take a close look at **lstm_pred**.

```
def lstm_pred(p, np, c):
    series = make_series(p, c)
    X = series.values
    supervised = timeseries_to_supervised(X, 1)
    supervised_values = supervised.values

    # Split data into train and test-sets
    train, test = supervised_values[0:-np], supervised_values[-np:]

    # Transform the scale of the data
    scaler, train_scaled, test_scaled = scale(train, test)

    # Fit the model
    lstm_model = fit_lstm(train_scaled, 1, 100, 1)

    # Forecast the entire training dataset to build up state for forecasting
    train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)
    lstm_model.predict(train_reshaped, batch_size=1)

    # Walk-forward validation on the test data
    yhat_sum = 0
    for i in range(len(test_scaled)):
        # Make one-step forecast
        X, y = test_scaled[i, 0:-1], test_scaled[i, -1]
        yhat = forecast_lstm(lstm_model, 1, X)
        # Invert scaling
        yhat = invert_scale(scaler, X, yhat)
        # Sum the weekly forecasts
        yhat_sum = yhat_sum + yhat

    return yhat_sum

```

Let's walk through this code to better understand how it works.  The first four lines are simply preparing the data for the model.

```
series = make_series(p, c)
X = series.values
supervised = timeseries_to_supervised(X, 1)
supervised_values = supervised.values
```
